{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/therev2/AgriSage/blob/main/CHSModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Y57JvDfK5hop",
        "outputId": "f7f98743-4836-4d6f-adb8-f118d4cbea3f"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n",
            "ERROR:root:Internal Python error in the inspect module.\n",
            "Below is the traceback from this internal error.\n",
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-d0a1edc951ad>\", line 7, in <cell line: 0>\n",
            "    ee.Authenticate()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ee/__init__.py\", line 156, in Authenticate\n",
            "    return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ee/oauth.py\", line 531, in authenticate\n",
            "    auth.authenticate_user()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\", line 260, in authenticate_user\n",
            "    _message.blocking_request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 176, in blocking_request\n",
            "    return read_reply_from_input(request_id, timeout_sec)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 96, in read_reply_from_input\n",
            "    time.sleep(0.025)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 997, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 417, in realpath\n",
            "  File \"<frozen posixpath>\", line 400, in abspath\n",
            "  File \"<frozen posixpath>\", line 64, in isabs\n",
            "KeyboardInterrupt\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"<ipython-input-1-d0a1edc951ad>\", line 7, in <cell line: 0>\n",
            "    ee.Authenticate()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ee/__init__.py\", line 156, in Authenticate\n",
            "    return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/ee/oauth.py\", line 531, in authenticate\n",
            "    auth.authenticate_user()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\", line 260, in authenticate_user\n",
            "    _message.blocking_request(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 176, in blocking_request\n",
            "    return read_reply_from_input(request_id, timeout_sec)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\", line 96, in read_reply_from_input\n",
            "    time.sleep(0.025)\n",
            "KeyboardInterrupt\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 3575, in run_code\n",
            "    self.showtraceback(running_compiled_code=True)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2101, in showtraceback\n",
            "    stb = self.InteractiveTB.structured_traceback(etype,\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1367, in structured_traceback\n",
            "    return FormattedTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1267, in structured_traceback\n",
            "    return VerboseTB.structured_traceback(\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1124, in structured_traceback\n",
            "    formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n",
            "                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1082, in format_exception_as_a_whole\n",
            "    last_unique, recursion_repeat = find_recursion(orig_etype, evalue, records)\n",
            "                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 382, in find_recursion\n",
            "    return len(records), 0\n",
            "           ^^^^^^^^^^^^\n",
            "TypeError: object of type 'NoneType' has no len()\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\", line 2099, in showtraceback\n",
            "    stb = value._render_traceback_()\n",
            "          ^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "AttributeError: 'TypeError' object has no attribute '_render_traceback_'\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 1101, in get_records\n",
            "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 248, in wrapped\n",
            "    return f(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\", line 281, in _fixed_getinnerframes\n",
            "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
            "                                          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1739, in getinnerframes\n",
            "    traceback_info = getframeinfo(tb, context)\n",
            "                     ^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 1684, in getframeinfo\n",
            "    filename = getsourcefile(frame) or getfile(frame)\n",
            "               ^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 948, in getsourcefile\n",
            "    module = getmodule(object, filename)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/inspect.py\", line 997, in getmodule\n",
            "    os.path.realpath(f)] = module.__name__\n",
            "    ^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen posixpath>\", line 416, in realpath\n",
            "  File \"<frozen posixpath>\", line 451, in _joinrealpath\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "TypeError",
          "evalue": "object of type 'NoneType' has no len()",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m<ipython-input-1-d0a1edc951ad>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAuthenticate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mee\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'agrofram'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/__init__.py\u001b[0m in \u001b[0;36mAuthenticate\u001b[0;34m(authorization_code, quiet, code_verifier, auth_mode, scopes, force)\u001b[0m\n\u001b[1;32m    155\u001b[0m   \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m   return oauth.authenticate(authorization_code, quiet, code_verifier, auth_mode,\n\u001b[0m\u001b[1;32m    157\u001b[0m                             scopes, force)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ee/oauth.py\u001b[0m in \u001b[0;36mauthenticate\u001b[0;34m(cli_authorization_code, quiet, cli_code_verifier, auth_mode, scopes, force)\u001b[0m\n\u001b[1;32m    530\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mauth\u001b[0m  \u001b[0;31m# pylint: disable=g-import-not-at-top # pytype: disable=import-error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 531\u001b[0;31m     \u001b[0mauth\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauthenticate_user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    532\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/auth.py\u001b[0m in \u001b[0;36mauthenticate_user\u001b[0;34m(clear_output, project_id)\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0muse_auth_ephem\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 260\u001b[0;31m       _message.blocking_request(\n\u001b[0m\u001b[1;32m    261\u001b[0m           \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 96\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     97\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3472\u001b[0m                         \u001b[0masy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3473\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0masync_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0masy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3474\u001b[0m                         \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1125\u001b[0m                                                                tb_offset)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2098\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2099\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'TypeError' object has no attribute '_render_traceback_'",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/async_helpers.py\u001b[0m in \u001b[0;36m_pseudo_sync_runner\u001b[0;34m(coro)\u001b[0m\n\u001b[1;32m     76\u001b[0m     \"\"\"\n\u001b[1;32m     77\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0mcoro\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_cell_async\u001b[0;34m(self, raw_cell, store_history, silent, shell_futures, transformed_cell, preprocessing_exc_tuple, cell_id)\u001b[0m\n\u001b[1;32m   3255\u001b[0m                     \u001b[0minteractivity\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'async'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3257\u001b[0;31m                 has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n\u001b[0m\u001b[1;32m   3258\u001b[0m                        interactivity=interactivity, compiler=compiler, result=result)\n\u001b[1;32m   3259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_ast_nodes\u001b[0;34m(self, nodelist, cell_name, interactivity, compiler, result)\u001b[0m\n\u001b[1;32m   3490\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3491\u001b[0m                 \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_before_exec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexc_info\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3492\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshowtraceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3493\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3494\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2099\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2100\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2101\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2102\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1368\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1369\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1265\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1266\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1267\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1268\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1269\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1140\u001b[0m         \u001b[0mchained_exc_ids\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1141\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1142\u001b[0;31m             formatted_exceptions += self.format_exception_as_a_whole(etype, evalue, etb, lines_of_context,\n\u001b[0m\u001b[1;32m   1143\u001b[0m                                                                      chained_exceptions_tb_offset)\n\u001b[1;32m   1144\u001b[0m             \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_parts_of_chained_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1080\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1081\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1082\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1083\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1084\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    380\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 382\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
          ]
        }
      ],
      "source": [
        "import ee\n",
        "import geemap\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project = 'agrofram')\n",
        "\n",
        "def create_date_ranges(year):\n",
        "    periods = []\n",
        "    # Months from November of current year to April of next year\n",
        "    months_config = [\n",
        "        (11, year),    # November current year\n",
        "        (12, year),    # December current year\n",
        "        (1, year+1),   # January next year\n",
        "        (2, year+1),   # February next year\n",
        "        (3, year+1),   # March next year\n",
        "        (4, year+1)    # April next year\n",
        "    ]\n",
        "\n",
        "    for month, year_to_use in months_config:\n",
        "        for day_start in [1, 11, 21]:\n",
        "            # Create start and end dates for 10-day periods\n",
        "            start_date = ee.Date(f'{year_to_use}-{month:02d}-{day_start:02d}')\n",
        "            end_date = start_date.advance(10, 'day')\n",
        "\n",
        "            periods.append({\n",
        "                'start': start_date,\n",
        "                'end': end_date,\n",
        "                'label': f'{year_to_use}_{month:02d}_{day_start:02d}'\n",
        "            })\n",
        "\n",
        "    return periods\n",
        "\n",
        "def load_and_process_ndvi(year, region):\n",
        "\n",
        "    # Get date ranges for the year\n",
        "    periods = create_date_ranges(year)\n",
        "\n",
        "    ndvi_composites = []\n",
        "\n",
        "    for period in periods:\n",
        "        # Load Sentinel-2 images for the period\n",
        "        collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "            .filterDate(period['start'], period['end']) \\\n",
        "            .filterBounds(region) \\\n",
        "            .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
        "\n",
        "        # If no images, append None\n",
        "        if collection.size().getInfo() == 0:\n",
        "            ndvi_composites.append({\n",
        "                'date': period['label'],\n",
        "                'ndvi': None\n",
        "            })\n",
        "            continue\n",
        "\n",
        "        # Calculate NDVI composite\n",
        "        ndvi_composite = collection \\\n",
        "            .map(lambda image: image.normalizedDifference(['B8', 'B4']).rename('NDVI')) \\\n",
        "            .mean()\n",
        "\n",
        "        # Extract mean NDVI value\n",
        "        mean_ndvi = ndvi_composite.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=region,\n",
        "            scale=10,\n",
        "            maxPixels=1e9\n",
        "        ).get('NDVI').getInfo()\n",
        "\n",
        "        ndvi_composites.append({\n",
        "            'date': period['label'],\n",
        "            'ndvi': mean_ndvi\n",
        "        })\n",
        "\n",
        "    return ndvi_composites\n",
        "\n",
        "def plot_ndvi_composites(ndvi_data):\n",
        "    \"\"\"\n",
        "    Plot NDVI composites across years\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Prepare data for plotting\n",
        "    all_dates = []\n",
        "    all_ndvis = []\n",
        "\n",
        "    for year_data in ndvi_data:\n",
        "        dates = [entry['date'] for entry in year_data if entry['ndvi'] is not None]\n",
        "        ndvis = [entry['ndvi'] for entry in year_data if entry['ndvi'] is not None]\n",
        "\n",
        "        plt.plot(dates, ndvis, marker='o', label=f'Year {dates[0][:4]}')\n",
        "\n",
        "        all_dates.extend(dates)\n",
        "        all_ndvis.extend(ndvis)\n",
        "\n",
        "    plt.title('NDVI Composites During Wheat Growing Season')\n",
        "    plt.xlabel('Time Periods')\n",
        "    plt.ylabel('Mean NDVI')\n",
        "    plt.xticks(rotation=45, ha='right')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return all_dates, all_ndvis\n",
        "\n",
        "def main():\n",
        "    # Define region of interest (example: Punjab, India)\n",
        "    xmin, ymin = 75.84399, 30.81936\n",
        "    xmax, ymax = 75.85511, 30.82714\n",
        "    punjab = ee.Geometry.Rectangle([75.84399, 30.81936,75.85511, 30.82714])\n",
        "\n",
        "    # Process NDVI for last 5 years\n",
        "    ndvi_data = []\n",
        "    for year in range(2018, 2025):\n",
        "        year_ndvi = load_and_process_ndvi(year, punjab)\n",
        "        ndvi_data.append(year_ndvi)\n",
        "\n",
        "    # Plot NDVI composites\n",
        "    dates, ndvis = plot_ndvi_composites(ndvi_data)\n",
        "\n",
        "    # Print out details of missing data\n",
        "    for year_data in ndvi_data:\n",
        "        missing_periods = [entry['date'] for entry in year_data if entry['ndvi'] is None]\n",
        "        if missing_periods:\n",
        "            print(f\"Missing periods: {missing_periods}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yiDoNjuS5piW"
      },
      "outputs": [],
      "source": [
        "import ee\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "ee.Authenticate()\n",
        "ee.Initialize(project = 'agrofram')\n",
        "\n",
        "def generate_full_timestamp_range(start_year, end_year):\n",
        "    \"\"\"\n",
        "    Generate complete timestamp range for wheat growing season\n",
        "    \"\"\"\n",
        "    timestamps = []\n",
        "    for year in range(start_year, end_year + 1):\n",
        "        # Wheat growing season from Nov to May\n",
        "        current_date = datetime(year, 11, 1)\n",
        "        season_end = datetime(year + 1, 5, 31)\n",
        "\n",
        "        while current_date <= season_end:\n",
        "            timestamps.append(current_date)\n",
        "            current_date += timedelta(days=10)\n",
        "\n",
        "    return timestamps\n",
        "\n",
        "def load_ndvi_for_period(start_date, end_date, region):\n",
        "\n",
        "    # Convert datetime to ee.Date\n",
        "    start = ee.Date(start_date.strftime('%Y-%m-%d'))\n",
        "    end = ee.Date(end_date.strftime('%Y-%m-%d'))\n",
        "\n",
        "    # Load Sentinel-2 images\n",
        "    collection = ee.ImageCollection('COPERNICUS/S2_SR_HARMONIZED') \\\n",
        "        .filterDate(start, end) \\\n",
        "        .filterBounds(region) \\\n",
        "        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', 30))\n",
        "\n",
        "    # If no images, return None\n",
        "    if collection.size().getInfo() == 0:\n",
        "        return None\n",
        "\n",
        "    # Calculate NDVI composite\n",
        "    ndvi_composite = collection \\\n",
        "        .map(lambda image: image.normalizedDifference(['B8', 'B4']).rename('NDVI')) \\\n",
        "        .mean()\n",
        "\n",
        "    # Extract mean NDVI value\n",
        "    try:\n",
        "        mean_ndvi = ndvi_composite.reduceRegion(\n",
        "            reducer=ee.Reducer.mean(),\n",
        "            geometry=region,\n",
        "            scale=10,\n",
        "            maxPixels=1e9\n",
        "        ).get('NDVI').getInfo()\n",
        "        return mean_ndvi\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "def create_ndvi_dataset(start_year, end_year):\n",
        "    \"\"\"\n",
        "    Create comprehensive NDVI dataset\n",
        "    \"\"\"\n",
        "  # Define region of interest (example: Punjab, India)\n",
        "    xmin, ymin = 75.84399, 30.81936\n",
        "    xmax, ymax = 75.85511, 30.82714\n",
        "    punjab = ee.Geometry.Rectangle([75.84399, 30.81936,75.85511, 30.82714])\n",
        "\n",
        "\n",
        "    # Generate full timestamp range\n",
        "    timestamps = generate_full_timestamp_range(start_year, end_year)\n",
        "\n",
        "    # Prepare data collection\n",
        "    data = []\n",
        "    for timestamp in timestamps:\n",
        "        # 10-day period\n",
        "        period_end = timestamp + timedelta(days=10)\n",
        "\n",
        "        # Calculate NDVI\n",
        "        ndvi = load_ndvi_for_period(timestamp, period_end, punjab)\n",
        "\n",
        "        data.append({\n",
        "            'timestamp': timestamp,\n",
        "            'NDVIi': ndvi\n",
        "        })\n",
        "\n",
        "    # Convert to DataFrame\n",
        "    df = pd.DataFrame(data)\n",
        "    df['year'] = df['timestamp'].dt.year\n",
        "    df['month'] = df['timestamp'].dt.month\n",
        "\n",
        "    return df\n",
        "\n",
        "def plot_ndvi_dataset(df):\n",
        "    \"\"\"\n",
        "    Plot NDVI dataset with missing values highlighted\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Group by year and plot\n",
        "    for year in df['year'].unique():\n",
        "        year_data = df[df['year'] == year]\n",
        "\n",
        "        # Plot available NDVI values\n",
        "        available = year_data[year_data['NDVIi'].notna()]\n",
        "        plt.plot(available['timestamp'], available['NDVIi'],\n",
        "                 marker='o', linestyle='-', label=f'Year {year}')\n",
        "\n",
        "        # Highlight missing values\n",
        "        missing = year_data[year_data['NDVIi'].isna()]\n",
        "        if not missing.empty:\n",
        "            plt.scatter(missing['timestamp'], [0]*len(missing),\n",
        "                        color='red', marker='x', s=100)\n",
        "\n",
        "    plt.title('NDVI Time Series with Missing Periods')\n",
        "    plt.xlabel('Timestamp')\n",
        "    plt.ylabel('NDVI Value')\n",
        "    plt.legend()\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gp_NZOjQQZM9",
        "outputId": "a4690eb6-f0f9-47fb-f9f0-459cecf98502"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'create_ndvi_dataset' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-f62eee87be14>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Generate NDVI dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mndvi_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_ndvi_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2018\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m    \u001b[0;31m# Plot and display results\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mresult_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_ndvi_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mndvi_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'create_ndvi_dataset' is not defined"
          ]
        }
      ],
      "source": [
        "\n",
        " # Generate NDVI dataset\n",
        "ndvi_df = create_ndvi_dataset(, 2024)\n",
        "\n",
        "    # Plot and display results\n",
        "result_df = plot_ndvi_dataset(ndvi_df)\n",
        "\n",
        "    # Print summary of missing data\n",
        "missing_summary = result_df[result_df['NDVIi'].isna()]\n",
        "print(\"Missing NDVI Periods:\")\n",
        "print(missing_summary[['timestamp', 'year', 'month']])\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ofCc8WUwTS_D"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nfOpFsflT3Hp"
      },
      "outputs": [],
      "source": [
        "print(result_df['NDVIi'].isna().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SWRiWYN1DsXb"
      },
      "outputs": [],
      "source": [
        "def interpolate_ndvi(df):\n",
        "\n",
        "    # Create a copy to avoid modifying original data\n",
        "    df_filtered = df.copy()\n",
        "\n",
        "    # Convert timestamp to datetime if it isn't already\n",
        "    df_filtered['timestamp'] = pd.to_datetime(df_filtered['timestamp'])\n",
        "\n",
        "    # Create seasonal features\n",
        "    df_filtered['month'] = df_filtered['timestamp'].dt.month\n",
        "    df_filtered['day'] = df_filtered['timestamp'].dt.day\n",
        "    df_filtered['day_of_year'] = df_filtered['timestamp'].dt.dayofyear\n",
        "\n",
        "    # Calculate seasonal medians for each day-month combination\n",
        "    seasonal_medians = df_filtered.groupby(['month', 'day'])['NDVIi'].transform('median')\n",
        "\n",
        "    # First pass: Fill missing values with seasonal medians\n",
        "    df_filtered['NDVIi_interpolated'] = df_filtered['NDVIi'].fillna(seasonal_medians)\n",
        "\n",
        "    # Second pass: Apply linear interpolation within each year\n",
        "    for year in df_filtered['year'].unique():\n",
        "        year_mask = df_filtered['year'] == year\n",
        "        df_filtered.loc[year_mask, 'NDVIi_interpolated'] = (\n",
        "            df_filtered.loc[year_mask, 'NDVIi_interpolated']\n",
        "            .interpolate(method='linear', limit_direction='forward', limit=30)  # Limit to 30 days forward\n",
        "        )\n",
        "\n",
        "    # Third pass: Fill any remaining NaN with seasonal patterns\n",
        "    remaining_nans = df_filtered['NDVIi_interpolated'].isna()\n",
        "    if remaining_nans.any():\n",
        "        # Calculate the average NDVI pattern across all years\n",
        "        seasonal_pattern = (\n",
        "            df_filtered.groupby('day_of_year')['NDVIi']\n",
        "            .mean()\n",
        "            .interpolate(method='cubic')  # Smooth the seasonal pattern\n",
        "        )\n",
        "\n",
        "        # Fill remaining NaNs with the seasonal pattern\n",
        "        for idx in df_filtered[remaining_nans].index:\n",
        "            day_of_year = df_filtered.loc[idx, 'day_of_year']\n",
        "            df_filtered.loc[idx, 'NDVIi_interpolated'] = seasonal_pattern[day_of_year]\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    # Plot original and interpolated data by year\n",
        "    years = df_filtered['year'].unique()\n",
        "    for year in years:\n",
        "        year_data = df_filtered[df_filtered['year'] == year]\n",
        "\n",
        "        plt.plot(year_data['timestamp'], year_data['NDVIi'],\n",
        "                marker='o', linestyle='', label=f'Year {year} - Original')\n",
        "        plt.plot(year_data['timestamp'], year_data['NDVIi_interpolated'],\n",
        "                marker='x', linestyle='-', label=f'Year {year} - Interpolated')\n",
        "\n",
        "    plt.title('NDVI: Original vs Interpolated')\n",
        "    plt.xlabel('Timestamp')\n",
        "    plt.ylabel('NDVI Value')\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.grid(True, alpha=0.3)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return df_filtered\n",
        "\n",
        "# Usage\n",
        "result = interpolate_ndvi(result_df)\n",
        "print(\"Missing values after interpolation:\", result['NDVIi_interpolated'].isna().sum())\n",
        "print(\"Total rows in dataset:\", len(result))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "mkvDsSvvSWlW"
      },
      "outputs": [],
      "source": [
        "print(result['NDVIi_interpolated'].isna())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gFnkbBNjUvQb"
      },
      "outputs": [],
      "source": [
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "ZWE-1aRXVXIz"
      },
      "outputs": [],
      "source": [
        "result = result.drop(columns= ['day'])\n",
        "result = result.drop(columns= ['NDVIi'])\n",
        "result = result.drop(columns= ['day_of_year'])\n",
        "print(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "DbT6fqB6fP1r"
      },
      "outputs": [],
      "source": [
        "def validate_growth_detection(df, cycles_df, cutoff_date='2025-02-07'):\n",
        "\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    cutoff = pd.to_datetime(cutoff_date)\n",
        "\n",
        "    for _, cycle in cycles_df.iterrows():\n",
        "        season_start = cycle['sowing_date']\n",
        "        season_end = min(\n",
        "            pd.to_datetime(season_start) + pd.Timedelta(days=210),\n",
        "            cutoff\n",
        "        )\n",
        "\n",
        "        # Skip if the entire season is beyond cutoff\n",
        "        if season_start > cutoff:\n",
        "            continue\n",
        "\n",
        "        season_data = df[\n",
        "            (df['timestamp'] >= season_start) &\n",
        "            (df['timestamp'] <= season_end)\n",
        "        ]\n",
        "\n",
        "        if not season_data.empty:\n",
        "            plt.plot(season_data['timestamp'], season_data['NDVIi_interpolated'],\n",
        "                    label=cycle['growing_season'])\n",
        "\n",
        "            # Only plot points if they're before cutoff\n",
        "            if cycle['growth_initiation_date'] <= cutoff:\n",
        "                plt.scatter(cycle['growth_initiation_date'], cycle['growth_initiation_ndvi'],\n",
        "                          marker='^', s=100, label=f\"{cycle['growing_season']} Growth Start\")\n",
        "\n",
        "            if cycle['peak_date'] <= cutoff:\n",
        "                plt.scatter(cycle['peak_date'], cycle['peak_ndvi'],\n",
        "                          marker='*', s=100, label=f\"{cycle['growing_season']} Peak\")\n",
        "\n",
        "    plt.axvline(x=cutoff, color='r', linestyle='--', label='Current Date')\n",
        "    plt.title('NDVI Cycles with Detected Growth Points')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('NDVI')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# We should also modify the analyze_crop_cycles function to respect the cutoff date\n",
        "def analyze_crop_cycles(df, cutoff_date='2025-02-07', min_change=0.02, consecutive_changes=2):\n",
        "    \"\"\"\n",
        "    Analyze crop cycles with proper date cutoff\n",
        "    \"\"\"\n",
        "    cycles = []\n",
        "    cutoff = pd.to_datetime(cutoff_date)\n",
        "\n",
        "    for year in df['year'].unique():\n",
        "        season_start = f\"{year}-11-01\"\n",
        "        season_end = min(\n",
        "            f\"{year+1}-05-31\",\n",
        "            cutoff_date\n",
        "        )\n",
        "\n",
        "        # Skip if season starts after cutoff\n",
        "        if pd.to_datetime(season_start) > cutoff:\n",
        "            continue\n",
        "\n",
        "        season_data = df[\n",
        "            (df['timestamp'] >= season_start) &\n",
        "            (df['timestamp'] <= season_end)\n",
        "        ].copy()\n",
        "\n",
        "        if not season_data.empty:\n",
        "            # Calculate NDVI changes and rolling mean to smooth out noise\n",
        "            season_data['ndvi_change'] = season_data['NDVIi_interpolated'].diff()\n",
        "            season_data['ndvi_rolling'] = season_data['NDVIi_interpolated'].rolling(3, center=True).mean()\n",
        "\n",
        "            # Find growth initiation using multiple methods\n",
        "            growth_start_idx = None\n",
        "\n",
        "\n",
        "            if growth_start_idx is None:\n",
        "                baseline = season_data['NDVIi_interpolated'].iloc[0:3].mean()\n",
        "                for i in range(len(season_data)):\n",
        "                    if season_data['NDVIi_interpolated'].iloc[i] > (baseline + 0.1):  # 0.1 threshold\n",
        "                        growth_start_idx = i\n",
        "                        break\n",
        "\n",
        "\n",
        "            # Find peak NDVI\n",
        "            peak_idx = season_data['ndvi_rolling'].idxmax()\n",
        "            peak_row = season_data.loc[peak_idx]\n",
        "\n",
        "            # Get sowing period\n",
        "            sowing_period = season_data[\n",
        "                season_data['timestamp'].dt.month == 11\n",
        "            ].iloc[0]\n",
        "\n",
        "            # Get growth initiation data\n",
        "            growth_initiation = season_data.iloc[growth_start_idx]['timestamp']\n",
        "            growth_ndvi = season_data.iloc[growth_start_idx]['NDVIi_interpolated']\n",
        "\n",
        "            cycles.append({\n",
        "                'growing_season': f\"{year}-{year+1}\",\n",
        "                'sowing_date': sowing_period['timestamp'],\n",
        "                'sowing_ndvi': sowing_period['NDVIi_interpolated'],\n",
        "                'growth_initiation_date': growth_initiation,\n",
        "                'growth_initiation_ndvi': growth_ndvi,\n",
        "                'peak_date': peak_row['timestamp'],\n",
        "                'peak_ndvi': peak_row['NDVIi_interpolated'],\n",
        "                'season_length_days': (season_data.iloc[-1]['timestamp'] - sowing_period['timestamp']).days,\n",
        "                'sowing_to_growth_days': (growth_initiation - sowing_period['timestamp']).days,\n",
        "                'growth_to_peak_days': (peak_row['timestamp'] - growth_initiation).days\n",
        "            })\n",
        "\n",
        "    return pd.DataFrame(cycles)\n",
        "\n",
        "# Function to validate and visualize the growth detection\n",
        "def validate_growth_detection(df, cycles_df):\n",
        "    \"\"\"Visualize the detected growth points for validation\"\"\"\n",
        "    plt.figure(figsize=(15, 8))\n",
        "\n",
        "    for _, cycle in cycles_df.iterrows():\n",
        "        season_start = cycle['sowing_date']\n",
        "        season_end = pd.to_datetime(season_start) + pd.Timedelta(days=210)\n",
        "\n",
        "        season_data = df[\n",
        "            (df['timestamp'] >= season_start) &\n",
        "            (df['timestamp'] <= season_end)\n",
        "        ]\n",
        "\n",
        "        plt.plot(season_data['timestamp'], season_data['NDVIi_interpolated'],\n",
        "                label=cycle['growing_season'])\n",
        "\n",
        "        # Plot growth initiation points\n",
        "        plt.scatter(cycle['growth_initiation_date'], cycle['growth_initiation_ndvi'],\n",
        "                   marker='^', s=100, label=f\"{cycle['growing_season']} Growth Start\")\n",
        "\n",
        "        # Plot peak points\n",
        "        plt.scatter(cycle['peak_date'], cycle['peak_ndvi'],\n",
        "                   marker='*', s=100, label=f\"{cycle['growing_season']} Peak\")\n",
        "\n",
        "    plt.title('NDVI Cycles with Detected Growth Points')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('NDVI')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.grid(True)\n",
        "    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Usage\n",
        "cycles = analyze_crop_cycles(result, min_change=0.015, consecutive_changes=2)\n",
        "validate_growth_detection(result, cycles)\n",
        "\n",
        "print(\"\\nCrop Cycle Analysis with Growth Initiation:\")\n",
        "print(cycles)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "12rRoK0eM6rK"
      },
      "outputs": [],
      "source": [
        "cycles = cycles.drop(6)  # 2025 season is not still completed , incomplete data can cause deviation in mean values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "UY12oE5JI2tt"
      },
      "outputs": [],
      "source": [
        "sowing_period_time = cycles['sowing_to_growth_days'].sum()\n",
        "total_years = 6\n",
        "avg_sowing_period = sowing_period_time / total_years\n",
        "print(f\"Average sowing period: {avg_sowing_period:.2f} days\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Coj5yENAMBu7"
      },
      "outputs": [],
      "source": [
        "growth_period_time = cycles['growth_to_peak_days'].sum()\n",
        "total_years = 6\n",
        "avg_growth_period = growth_period_time / total_years\n",
        "avg_growth_period += avg_sowing_period\n",
        "print(f\"Average growth period: {avg_growth_period:.2f} days\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "NsVVEItcMt4E"
      },
      "outputs": [],
      "source": [
        "harvest_period_time = cycles['season_length_days'].sum()\n",
        "total_years = 6\n",
        "avg_harvest_period = harvest_period_time / total_years\n",
        "avg_harvest_period -= 30       # We are considering april as harvesting time period\n",
        "print(f\"Average harvest period: {avg_harvest_period:.2f} days\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "SJzgcSxmOC4h"
      },
      "outputs": [],
      "source": [
        "threshold_ndvi = cycles['growth_initiation_ndvi'].mean()\n",
        "print(f\"Threshold NDVI for growth initiation: {threshold_ndvi:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1QPVsjFBOceB"
      },
      "outputs": [],
      "source": [
        "peak_ndvi = cycles['peak_ndvi'].max()                           ## yield pred can tell us what will be best way to select peak NDVI value\n",
        "print(f\"Peak NDVI for peak: {peak_ndvi:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "jyo4kfo-OmMh"
      },
      "outputs": [],
      "source": [
        "min_ndvi = cycles['sowing_ndvi'].mean()\n",
        "print(f\"Minimum NDVI for sowing: {min_ndvi:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "0rJX3yFpOvtP"
      },
      "outputs": [],
      "source": [
        "active_growth_ndvi = threshold_ndvi + (peak_ndvi - threshold_ndvi) / 2\n",
        "print(f\"Active growth NDVI: {active_growth_ndvi:.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "1-g9dXl7c8q9"
      },
      "outputs": [],
      "source": [
        "print(\"NDVI Data Statistics:\")\n",
        "print(result['NDVIi_interpolated'].describe())\n",
        "print(\"\\nStandard Deviation:\", result['NDVIi_interpolated'].std())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yfbA8FkShKFo"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "\n",
        "def analyze_threshold_impacts(df, thresholds=[0.5, 1.0, 1.15, 1.5, 2]):\n",
        "    std_dev = df['NDVIi_interpolated'].std()\n",
        "    window_size = 3\n",
        "\n",
        "    # Create figure\n",
        "    fig, axs = plt.subplots(len(thresholds), 1, figsize=(15, 5*len(thresholds)))\n",
        "    fig.suptitle('NDVI Anomaly Detection with Different Thresholds', fontsize=16, y=0.95)\n",
        "\n",
        "    results = []\n",
        "\n",
        "    for idx, threshold in enumerate(thresholds):\n",
        "        # Calculate rolling statistics\n",
        "        rolling_mean = df['NDVIi_interpolated'].rolling(window=window_size).mean()\n",
        "        rolling_std = df['NDVIi_interpolated'].rolling(window=window_size).std()\n",
        "\n",
        "        # Define bounds\n",
        "        upper_bound = rolling_mean + (threshold * rolling_std)\n",
        "        lower_bound = rolling_mean - (threshold * rolling_std)\n",
        "\n",
        "        # Detect anomalies\n",
        "        anomalies = df[\n",
        "            (df['NDVIi_interpolated'] > upper_bound) |\n",
        "            (df['NDVIi_interpolated'] < lower_bound)\n",
        "        ]\n",
        "\n",
        "        # Calculate actual deviation range\n",
        "        actual_deviation = threshold * std_dev\n",
        "\n",
        "        # Store results\n",
        "        results.append({\n",
        "            'threshold': threshold,\n",
        "            'num_anomalies': len(anomalies),\n",
        "            'percentage': (len(anomalies) / len(df)) * 100,\n",
        "            'deviation_range': actual_deviation\n",
        "        })\n",
        "\n",
        "        # Plot\n",
        "        ax = axs[idx]\n",
        "\n",
        "        # Plot original NDVI\n",
        "        for year in df['year'].unique():\n",
        "            year_data = df[df['year'] == year]\n",
        "            ax.plot(year_data['timestamp'], year_data['NDVIi_interpolated'],\n",
        "                   label=f'Year {year}', alpha=0.7)\n",
        "\n",
        "        # Plot anomalies\n",
        "        ax.scatter(anomalies['timestamp'], anomalies['NDVIi_interpolated'],\n",
        "                  color='red', s=100, label='Anomalies', zorder=5)\n",
        "\n",
        "        ax.set_title(f'Threshold = {threshold} ({actual_deviation:.3f} NDVI units)\\n'\n",
        "                    f'Number of anomalies: {len(anomalies)} ({(len(anomalies)/len(df)*100):.1f}% of data)')\n",
        "        ax.set_xlabel('Time')\n",
        "        ax.set_ylabel('NDVI Value')\n",
        "        ax.legend()\n",
        "        ax.grid(True, alpha=0.3)\n",
        "\n",
        "        # Format dates\n",
        "        ax.xaxis.set_major_formatter(DateFormatter(\"%Y-%m\"))\n",
        "        plt.setp(ax.xaxis.get_majorticklabels(), rotation=45)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print detailed analysis\n",
        "    results_df = pd.DataFrame(results)\n",
        "    print(\"\\nDetailed Threshold Analysis:\")\n",
        "    print(\"---------------------------\")\n",
        "    for _, row in results_df.iterrows():\n",
        "        print(f\"\\nThreshold: {row['threshold']}\")\n",
        "        print(f\"Allowed deviation: {row['deviation_range']:.3f} NDVI units\")\n",
        "        print(f\"Number of anomalies: {row['num_anomalies']}\")\n",
        "        print(f\"Percentage of data flagged: {row['percentage']:.1f}%\")\n",
        "        print(f\"Interpretation: {'Too sensitive' if row['percentage'] > 20 else 'Good sensitivity' if 5 <= row['percentage'] <= 20 else 'May miss anomalies'}\")\n",
        "\n",
        "# Run the analysis\n",
        "analyze_threshold_impacts(result)\n",
        "\n",
        "# Print basic NDVI statistics for reference\n",
        "print(\"\\nNDVI Data Distribution:\")\n",
        "print(\"----------------------\")\n",
        "stats = result['NDVIi_interpolated'].describe()\n",
        "print(stats)\n",
        "print(f\"\\nStandard Deviation: {result['NDVIi_interpolated'].std():.3f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "RBJpsqoOSOfp",
        "outputId": "0811d183-0b86-4dd5-afba-1faa6884e4ac"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'result' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-89e372b1d00f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;31m# Use the function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m \u001b[0manomalies\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdetect_and_plot_anomalies\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'result' is not defined"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.dates import DateFormatter\n",
        "\n",
        "def detect_and_plot_anomalies(df, window_size=3, std_threshold = 1.2):\n",
        "    # Calculate rolling statistics\n",
        "    rolling_mean = df['NDVIi_interpolated'].rolling(window=window_size).mean()\n",
        "    rolling_std = df['NDVIi_interpolated'].rolling(window=window_size).std()\n",
        "\n",
        "    # Define upper and lower bounds\n",
        "    upper_bound = rolling_mean + (std_threshold * rolling_std)\n",
        "    lower_bound = rolling_mean - (std_threshold * rolling_std)\n",
        "\n",
        "    # Detect anomalies\n",
        "    anomalies = df[\n",
        "        (df['NDVIi_interpolated'] > upper_bound) |\n",
        "        (df['NDVIi_interpolated'] < lower_bound)\n",
        "    ]\n",
        "\n",
        "    # Create the visualization\n",
        "    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(15, 12), height_ratios=[2, 1])\n",
        "\n",
        "    # Plot 1: Original NDVI with anomalies\n",
        "    for year in df['year'].unique():\n",
        "        year_data = df[df['year'] == year]\n",
        "        ax1.plot(year_data['timestamp'], year_data['NDVIi_interpolated'],\n",
        "                 label=f'Year {year}', alpha=0.7)\n",
        "\n",
        "    # Highlight anomalies\n",
        "    ax1.scatter(anomalies['timestamp'], anomalies['NDVIi_interpolated'],\n",
        "                color='red', s=100, label='Anomalies', zorder=5)\n",
        "\n",
        "    ax1.set_title('NDVI Values with Detected Anomalies')\n",
        "    ax1.set_xlabel('Time')\n",
        "    ax1.set_ylabel('NDVI Value')\n",
        "    ax1.legend()\n",
        "    ax1.grid(True, alpha=0.3)\n",
        "\n",
        "    # Plot 2: Deviation from rolling mean\n",
        "    deviation = df['NDVIi_interpolated'] - rolling_mean\n",
        "    ax2.plot(df['timestamp'], deviation, label='Deviation from mean', color='blue', alpha=0.6)\n",
        "    ax2.fill_between(df['timestamp'],\n",
        "                     -std_threshold * rolling_std,\n",
        "                     std_threshold * rolling_std,\n",
        "                     color='gray', alpha=0.2, label='Normal range')\n",
        "\n",
        "    # Highlight anomalous deviations\n",
        "    anomalous_deviations = deviation[\n",
        "        (df['NDVIi_interpolated'] > upper_bound) |\n",
        "        (df['NDVIi_interpolated'] < lower_bound)\n",
        "    ]\n",
        "    ax2.scatter(anomalous_deviations.index,\n",
        "                anomalous_deviations.values,\n",
        "                color='red', s=100, label='Anomalies', zorder=5)\n",
        "\n",
        "    ax2.set_title('Deviation from Rolling Mean')\n",
        "    ax2.set_xlabel('Time')\n",
        "    ax2.set_ylabel('NDVI Deviation')\n",
        "    ax2.legend()\n",
        "    ax2.grid(True, alpha=0.3)\n",
        "\n",
        "    # Format dates on x-axis\n",
        "    date_formatter = DateFormatter(\"%Y-%m\")\n",
        "    ax1.xaxis.set_major_formatter(date_formatter)\n",
        "    ax2.xaxis.set_major_formatter(date_formatter)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Print anomaly statistics\n",
        "    print(\"\\nAnomaly Statistics:\")\n",
        "    print(f\"Total number of anomalies detected: {len(anomalies)}\")\n",
        "    if not anomalies.empty:\n",
        "          print(\"\\nAnomalous dates and values:\")\n",
        "    for idx, row in anomalies.iterrows():\n",
        "        print(f\"Date: {row['timestamp'].strftime('%Y-%m-%d')}, \"\n",
        "              f\"NDVI: {row['NDVIi_interpolated']:.3f}\")\n",
        "\n",
        "    return anomalies\n",
        "\n",
        "# Use the function\n",
        "anomalies = detect_and_plot_anomalies(result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "pXxT4QME8kN4"
      },
      "outputs": [],
      "source": [
        "result_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3k-6pC5Fi6BM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import timedelta\n",
        "\n",
        "def create_sequences(data, seq_length):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - seq_length):\n",
        "        X.append(data[i:(i + seq_length)])\n",
        "        y.append(data[i + seq_length])\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "def prepare_data(df, seq_length=6):\n",
        "    train_data = df[df['year'] < 2024]['NDVIi_interpolated'].values\n",
        "    test_data = df[df['year'] >= 2024]['NDVIi_interpolated'].values\n",
        "    test_dates = df[df['year'] >= 2024]['timestamp'].values  # Get test set dates\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train_scaled = scaler.fit_transform(train_data.reshape(-1, 1))\n",
        "    test_scaled = scaler.transform(test_data.reshape(-1, 1))\n",
        "\n",
        "    X_train, y_train = create_sequences(train_scaled, seq_length)\n",
        "    X_test, y_test = create_sequences(test_scaled, seq_length)\n",
        "\n",
        "    return X_train, y_train, X_test, y_test, scaler, test_dates[-1]\n",
        "\n",
        "def build_lstm_model(seq_length):\n",
        "    model = Sequential([\n",
        "        LSTM(64, activation='relu', input_shape=(seq_length, 1), return_sequences=True),\n",
        "        Dropout(0.2),\n",
        "        LSTM(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dense(1)\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer='adam', loss='mse')\n",
        "    return model\n",
        "\n",
        "def evaluate_predictions(y_true, y_pred):\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    mae = mean_absolute_error(y_true, y_pred)\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    # Calculate accuracy as 1 - normalized RMSE\n",
        "    accuracy = 1 - (rmse / (np.max(y_true) - np.min(y_true)))\n",
        "\n",
        "    return {\n",
        "        'RMSE': rmse,\n",
        "        'MAE': mae,\n",
        "        'R2': r2,\n",
        "        'Accuracy': accuracy\n",
        "    }\n",
        "\n",
        "def plot_results(actual, predicted, title='NDVI Predictions'):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.plot(actual, label='Actual', marker='o')\n",
        "    plt.plot(predicted, label='Predicted', marker='x')\n",
        "    plt.title(title)\n",
        "    plt.xlabel('Time Steps')\n",
        "    plt.ylabel('NDVI')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "\n",
        "# Predict next 10 days NDVI\n",
        "\n",
        "def predict_next_10_days(model, last_sequence, scaler, last_date):\n",
        "    predictions = []\n",
        "    dates = []\n",
        "    input_seq = last_sequence.copy()\n",
        "\n",
        "    for i in range(1):  # Predict for next 10 days which will be calculted to give as a new predicted ndvi composite\n",
        "        pred = model.predict(input_seq.reshape(1, -1, 1))\n",
        "        pred_inv = scaler.inverse_transform(pred)\n",
        "        predictions.append(pred_inv[0][0])\n",
        "\n",
        "        # Convert last_date to datetime if needed\n",
        "        last_date = pd.to_datetime(last_date)\n",
        "        dates.append(last_date + timedelta(days=i + 1))  # Generate future timestamps\n",
        "\n",
        "        input_seq = np.append(input_seq[1:], pred)\n",
        "\n",
        "    return predictions, dates\n",
        "\n",
        "\n",
        "# Main execution\n",
        "def train_and_evaluate(df):\n",
        "    # Prepare data\n",
        "    X_train, y_train, X_test, y_test, scaler,last_test_date = prepare_data(df)\n",
        "\n",
        "    # Build and train model\n",
        "    model = build_lstm_model(X_train.shape[1])\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        epochs=100,\n",
        "        batch_size=32,\n",
        "        validation_split=0.2,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Make predictions\n",
        "    train_pred = model.predict(X_train)\n",
        "    test_pred = model.predict(X_test)\n",
        "\n",
        "    # Inverse transform predictions\n",
        "    train_pred = scaler.inverse_transform(train_pred)\n",
        "    test_pred = scaler.inverse_transform(test_pred)\n",
        "    y_train_orig = scaler.inverse_transform(y_train)\n",
        "    y_test_orig = scaler.inverse_transform(y_test)\n",
        "\n",
        "    # Evaluate model\n",
        "    train_metrics = evaluate_predictions(y_train_orig, train_pred)\n",
        "    test_metrics = evaluate_predictions(y_test_orig, test_pred)\n",
        "\n",
        "    # Plot results\n",
        "    plot_results(y_test_orig, test_pred, 'NDVI Predictions for 2024 (Test Set)')\n",
        "\n",
        "    # Predict next 10 days NDVI\n",
        "    last_sequence = X_test[-1]  # Get last sequence from test data\n",
        "    next_10_days_predictions, next_10_days_dates = predict_next_10_days(model, last_sequence, scaler, last_test_date)\n",
        "\n",
        "    global global_next_10_days_prediction\n",
        "    global_next_10_days_prediction = list(zip(next_10_days_dates, next_10_days_predictions))\n",
        "\n",
        "    print(\"Next 10 Days NDVI Predictions:\", next_10_days_predictions)\n",
        "\n",
        "    return train_metrics, test_metrics, model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "-uYCU9SDl01q"
      },
      "outputs": [],
      "source": [
        "train_metrics, test_metrics, model = train_and_evaluate(result)\n",
        "print(\"\\nTraining Metrics:\", train_metrics)\n",
        "print(\"\\nTest Metrics:\", test_metrics)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "zJDBc7bkow_f"
      },
      "outputs": [],
      "source": [
        "global_next_10_days_prediction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "yDLFiGaio7pY"
      },
      "outputs": [],
      "source": [
        "pred_timestamp , ndvi_prediction = global_next_10_days_prediction[0]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "90Jay8TEKZaR"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load NDWI predictions\n",
        "ndwi_predictions = pd.read_csv('/content/drive/My Drive/NDWI_predictions.csv')\n",
        "\n",
        "# Now use ndwi_predictions for further analysis\n",
        "print(ndwi_predictions)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "cj5FB32_Rnj7"
      },
      "outputs": [],
      "source": [
        "## Feature Engg and Data Cleaning -> Try adv techniques"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "riGCuJlNQ_ub"
      },
      "outputs": [],
      "source": [
        "## Weather prediction to make preventions from damage -> Weather Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "olOma5tPNoPY"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load and print results\n",
        "file_path = \"/content/drive/My Drive/NDWI_results.txt\"\n",
        "with open(file_path, \"r\") as file:\n",
        "    results = file.read()\n",
        "\n",
        "print(\"Loaded NDWI Results:\\n\")\n",
        "print(results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "EQH2FzHkN8vB"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load NDWI predictions\n",
        "ndwi_predictions_dataset = pd.read_csv('/content/drive/My Drive/NDWI_predictions.csv')\n",
        "\n",
        "ndwi_prediction = ndwi_predictions_dataset['Predicted_NDWI']\n",
        "pred_timestamp = ndwi_predictions_dataset['Date']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "sP6-lUtYOMUW"
      },
      "outputs": [],
      "source": [
        "average_sowing_period_ndwi = 43.33\n",
        "average_growth_period_ndwi = 125.00\n",
        "average_harvest_period = 180.00\n",
        "threshold_ndwi_for_growth_initiation = -0.328\n",
        "peak_ndwi_for_peak = -0.756\n",
        "minimum_ndwi_for_sowing = -0.311\n",
        "active_growth_ndwi = -0.605"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9DarE9KnSSB_"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Thresholds from historical data\n",
        "THRESHOLDS = {\n",
        "    'minimal_growth': min_ndvi,\n",
        "    'growth_initiation': threshold_ndvi,\n",
        "    'active_growth': active_growth_ndvi,\n",
        "    'peak_growth': peak_ndvi\n",
        "}\n",
        "\n",
        "# Define seasonal growth stages (months)\n",
        "SEASONS = {\n",
        "    'sowing': [11],\n",
        "    'growth_initiation': [12, 1],\n",
        "    'peak_time': [1, 2],\n",
        "    'just_before_harvest': [3],\n",
        "    'harvest': [4]\n",
        "}\n",
        "\n",
        "# Function to analyze NDVI predictions\n",
        "def analyze_predictions(predictions, dates):\n",
        "    analysis_results = []\n",
        "\n",
        "    for pred, date in zip(predictions, dates):\n",
        "        month = date.month\n",
        "        status = {}\n",
        "        status['date'] = date.strftime('%Y-%m-%d')\n",
        "        status['predicted_ndvi'] = round(pred, 3)\n",
        "\n",
        "        #  Condition: If the date is outside the farming season\n",
        "        if month not in sum(SEASONS.values(), []):\n",
        "            status['condition'] = 'OUT OF SEASON'\n",
        "            status['reason'] = (\n",
        "                \" It's not the farming season right now. Take a break and plan ahead!\"\n",
        "            )\n",
        "            analysis_results.append(status)\n",
        "            continue\n",
        "\n",
        "        #  Condition 1: Severe Crop Stress (Drought, Pests, or Disease)\n",
        "        if pred < THRESHOLDS['minimal_growth']:\n",
        "            status['condition'] = 'CRITICAL'\n",
        "            status['reason'] = (\n",
        "                \"NDVI is below the minimum threshold.  Immediate action needed! \"\n",
        "                \"Possible causes: Severe water stress (drought), pest infestation, \"\n",
        "                \"disease outbreak, or complete crop failure. Farmers should check irrigation, \"\n",
        "                \"apply pest control, and inspect crops for diseases.\"\n",
        "            )\n",
        "            analysis_results.append(status)\n",
        "            continue\n",
        "\n",
        "        #  Condition 2: Healthy Growth (Ideal for the Current Stage)\n",
        "        if pred > THRESHOLDS['active_growth']:\n",
        "            if month in SEASONS['growth_initiation'] + SEASONS['just_before_harvest']:\n",
        "                if month in SEASONS['peak_time'] and pred < 0.80:\n",
        "                    status['condition'] = 'NOT SO GOOD'\n",
        "                    status['reason'] = (\n",
        "                        \"NDVI is lower than expected during peak growth.  This might indicate \"\n",
        "                        \"delayed growth, nutrient deficiency, or mild water stress. \"\n",
        "                        \"Farmers should check soil nutrients and irrigation schedules.\"\n",
        "                    )\n",
        "                else:\n",
        "                    status['condition'] = 'HEALTHY'\n",
        "                    status['reason'] = (\n",
        "                        \"NDVI indicates strong crop growth for this period.  Keep monitoring \"\n",
        "                        \"soil moisture and nutrients to maintain optimal growth.\"\n",
        "                    )\n",
        "\n",
        "        #  Condition 3: Moderate Growth (Potential Issues)\n",
        "        elif THRESHOLDS['growth_initiation'] < pred <= THRESHOLDS['active_growth']:\n",
        "            if month in SEASONS['peak_time'] or month in SEASONS['sowing'] or month in SEASONS['harvest']:\n",
        "                status['condition'] = 'WARNING'\n",
        "                status['reason'] = (\n",
        "                    \"NDVI is too low for this period.  Possible causes: Stunted growth, poor germination, \"\n",
        "                    \"nutrient deficiency, or early senescence. Farmers should apply fertilizers, \"\n",
        "                    \"check pest infestation, and monitor for any environmental stress.\"\n",
        "                )\n",
        "            else:\n",
        "                status['condition'] = 'MODERATE'\n",
        "                status['reason'] = (\n",
        "                    \"NDVI suggests normal growth, but it's not optimal.  Farmers should ensure proper \"\n",
        "                    \"irrigation and fertilizer use for better crop health.\"\n",
        "                )\n",
        "\n",
        "        #  Condition 4: Pre-Harvest or Sowing Stage (Low NDVI is Expected)\n",
        "        elif pred <= THRESHOLDS['growth_initiation']:\n",
        "            if month in SEASONS['sowing'] or month in SEASONS['harvest']:\n",
        "                status['condition'] = 'EXPECTED'\n",
        "                status['reason'] = (\n",
        "                    \"NDVI is low, but this is normal for the sowing or harvest period.  No immediate \"\n",
        "                    \"action needed, but monitor closely for any unexpected decline.\"\n",
        "                )\n",
        "            else:\n",
        "                status['condition'] = 'BAD'\n",
        "                status['reason'] = (\n",
        "                    \"NDVI is too low for this growth period.  This might indicate poor establishment, \"\n",
        "                    \"severe stress, or crop damage. Farmers should inspect fields and apply necessary interventions.\"\n",
        "                )\n",
        "\n",
        "        #  Condition 5: Drought Stress Detection\n",
        "        if pred < 0.35 and month in SEASONS['growth_initiation'] + SEASONS['peak_time']:\n",
        "            status['additional_warning'] = \"Drought Stress Detected\"\n",
        "            status['suggestion'] = (\n",
        "                \" NDVI suggests possible drought conditions. Farmers should increase irrigation, \"\n",
        "                \"check soil moisture, and avoid excessive fertilization.\"\n",
        "            )\n",
        "\n",
        "        #  Condition 6: Pest Infestation Warning\n",
        "        if pred < 0.40 and month in SEASONS['growth_initiation'] and pred < (THRESHOLDS['growth_initiation'] + 0.05):\n",
        "            status['additional_warning'] = \"Pest Infestation Possible\"\n",
        "            status['suggestion'] = (\n",
        "                \" NDVI suggests potential pest damage. Farmers should inspect fields for pest signs, \"\n",
        "                \"use eco-friendly pesticides, and monitor for further decline.\"\n",
        "            )\n",
        "\n",
        "        #  Condition 7: Disease Detection\n",
        "        if pred > 0.55 and month in SEASONS['growth_initiation'] and pred < (THRESHOLDS['peak_growth'] - 0.10):\n",
        "            status['additional_warning'] = \"Disease Symptoms Detected\"\n",
        "            status['suggestion'] = (\n",
        "                \" NDVI suggests early-stage disease symptoms. Farmers should check leaves for fungal/bacterial infections, \"\n",
        "                \"apply fungicides if needed, and avoid water stagnation.\"\n",
        "            )\n",
        "\n",
        "        analysis_results.append(status)\n",
        "\n",
        "    return pd.DataFrame(analysis_results)\n",
        "\n",
        "\n",
        "# Visualization Function\n",
        "def visualize_predictions(analysis_df):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Define color mapping for conditions\n",
        "    color_map = {\n",
        "        'HEALTHY': 'green',\n",
        "        'EXPECTED': 'blue',\n",
        "        'MODERATE': 'orange',\n",
        "        'WARNING': 'darkorange',\n",
        "        'NOT SO GOOD': 'red',\n",
        "        'BAD': 'brown',\n",
        "        'CRITICAL': 'black'\n",
        "    }\n",
        "\n",
        "    # Plot points with colors based on condition\n",
        "    for condition in color_map.keys():\n",
        "        mask = analysis_df['condition'] == condition\n",
        "        if mask.any():\n",
        "            plt.scatter(pd.to_datetime(analysis_df[mask]['date']),\n",
        "                        analysis_df[mask]['predicted_ndvi'],\n",
        "                        label=condition,\n",
        "                        color=color_map[condition])\n",
        "\n",
        "    plt.plot(pd.to_datetime(analysis_df['date']),\n",
        "             analysis_df['predicted_ndvi'],\n",
        "             'b--', alpha=0.5)\n",
        "\n",
        "    plt.title('NDVI Predictions for Next 10 Days')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('NDVI')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Run Analysis\n",
        "def run_prediction_analysis(predictions, dates):\n",
        "    \"\"\"\n",
        "    Run the complete prediction and analysis pipeline\n",
        "    \"\"\"\n",
        "    analysis_df = analyze_predictions(predictions, dates)\n",
        "\n",
        "    print(\"\\nPrediction Analysis Results:\")\n",
        "    print(\"=\" * 80)\n",
        "    for _, row in analysis_df.iterrows():\n",
        "        print(f\"\\nDate: {row['date']}\")\n",
        "        print(f\"Predicted NDVI: {row['predicted_ndvi']}\")\n",
        "        print(f\"Condition: {row['condition']}\")\n",
        "        print(f\"Reason: {row['reason']}\")\n",
        "        if 'additional_warning' in row:\n",
        "            print(f\" {row['additional_warning']}: {row['suggestion']}\")\n",
        "\n",
        "    visualize_predictions(analysis_df)\n",
        "    return analysis_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "w-LLAPJ5jx3v"
      },
      "outputs": [],
      "source": [
        "run_prediction_analysis([ndvi_prediction], [pred_timestamp])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "AsKZkpQlq7hO"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Thresholds from historical data\n",
        "NDWI_THRESHOLDS = {\n",
        "    'drought': minimum_ndwi_for_sowing,  # Severe water stress threshold\n",
        "    'low_water': threshold_ndwi_for_growth_initiation,  # Below-average water availability\n",
        "    'adequate_water': active_growth_ndwi,  # Normal irrigation conditions\n",
        "    'excess_water': peak_ndwi_for_peak  # High water availability\n",
        "}\n",
        "\n",
        "# Define seasonal water demand stages (months)\n",
        "NDWI_SEASONS = {\n",
        "    'sowing': [11],\n",
        "    'growth_initiation': [12, 1],\n",
        "    'peak_water_demand': [1, 2],\n",
        "    'pre_harvest': [3],\n",
        "    'harvest': [4]\n",
        "}\n",
        "\n",
        "def analyze_ndwi_predictions(predictions, dates):\n",
        "    analysis_results = []\n",
        "\n",
        "    for pred, date in zip(predictions, dates):\n",
        "        month = date.month\n",
        "        status = {}\n",
        "        status['date'] = date.strftime('%Y-%m-%d')\n",
        "        status['predicted_ndwi'] = round(pred, 3)\n",
        "\n",
        "        #  Condition 1: Severe Drought Risk\n",
        "        if pred < NDWI_THRESHOLDS['drought']:\n",
        "            status['condition'] = 'CRITICAL'\n",
        "            status['reason'] = (\n",
        "                \"NDWI is extremely low!  Severe drought conditions detected. Immediate irrigation needed.\"\n",
        "            )\n",
        "            analysis_results.append(status)\n",
        "            continue\n",
        "\n",
        "        #  Condition 2: Ideal Water Availability\n",
        "        if pred > NDWI_THRESHOLDS['adequate_water']:\n",
        "            if month in NDWI_SEASONS['growth_initiation'] + NDWI_SEASONS['pre_harvest']:\n",
        "                status['condition'] = 'HEALTHY'\n",
        "                status['reason'] = (\n",
        "                    \"NDWI indicates sufficient water for crop growth.  No urgent action required.\"\n",
        "                )\n",
        "\n",
        "        #  Condition 3: Low Water Availability\n",
        "        elif NDWI_THRESHOLDS['low_water'] < pred <= NDWI_THRESHOLDS['adequate_water']:\n",
        "            status['condition'] = 'MODERATE'\n",
        "            status['reason'] = (\n",
        "                \"NDWI suggests moderate water levels.  Farmers should monitor soil moisture and consider light irrigation.\"\n",
        "            )\n",
        "\n",
        "        #  Condition 4: Pre-Harvest or Sowing Stage (Low NDWI is Normal)\n",
        "        elif pred <= NDWI_THRESHOLDS['low_water']:\n",
        "            if month in NDWI_SEASONS['sowing'] or month in NDWI_SEASONS['harvest']:\n",
        "                status['condition'] = 'EXPECTED'\n",
        "                status['reason'] = (\n",
        "                    \"NDWI is low, but this is normal for the sowing or harvest period.  No immediate action needed.\"\n",
        "                )\n",
        "            else:\n",
        "                status['condition'] = 'BAD'\n",
        "                status['reason'] = (\n",
        "                    \"NDWI is too low for this period!  Farmers should inspect irrigation systems.\"\n",
        "                )\n",
        "\n",
        "        #  Condition 5: Out of Farming Season Alert\n",
        "        if month not in sum(NDWI_SEASONS.values(), []):\n",
        "            status['condition'] = 'OFF-SEASON'\n",
        "            status['reason'] = \" It's not farming season! Farmers should focus on soil preparation or crop planning.\"\n",
        "\n",
        "        analysis_results.append(status)\n",
        "\n",
        "    return pd.DataFrame(analysis_results)\n",
        "\n",
        "def visualize_ndwi_predictions(analysis_df):\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    color_map = {\n",
        "        'HEALTHY': 'green',\n",
        "        'EXPECTED': 'blue',\n",
        "        'MODERATE': 'orange',\n",
        "        'BAD': 'red',\n",
        "        'CRITICAL': 'black',\n",
        "        'OFF-SEASON': 'gray'\n",
        "    }\n",
        "\n",
        "    for condition in color_map.keys():\n",
        "        mask = analysis_df['condition'] == condition\n",
        "        if mask.any():\n",
        "            plt.scatter(pd.to_datetime(analysis_df[mask]['date']),\n",
        "                        analysis_df[mask]['predicted_ndwi'],\n",
        "                        label=condition,\n",
        "                        color=color_map[condition])\n",
        "\n",
        "    plt.plot(pd.to_datetime(analysis_df['date']),\n",
        "             analysis_df['predicted_ndwi'],\n",
        "             'b--', alpha=0.5)\n",
        "\n",
        "    plt.title('NDWI Predictions for Next 10 Days')\n",
        "    plt.xlabel('Date')\n",
        "    plt.ylabel('NDWI')\n",
        "    plt.legend()\n",
        "    plt.grid(True)\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "def run_ndwi_analysis(predictions, dates):\n",
        "    analysis_df = analyze_ndwi_predictions(predictions, dates)\n",
        "    print(\"\\nNDWI Prediction Analysis Results:\")\n",
        "    print(\"=\" * 80)\n",
        "    for _, row in analysis_df.iterrows():\n",
        "        print(f\"\\nDate: {row['date']}\")\n",
        "        print(f\"Predicted NDWI: {row['predicted_ndwi']}\")\n",
        "        print(f\"Condition: {row['condition']}\")\n",
        "        print(f\"Reason: {row['reason']}\")\n",
        "\n",
        "    visualize_ndwi_predictions(analysis_df)\n",
        "    return analysis_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "3VmdhCObxuIC"
      },
      "outputs": [],
      "source": [
        "run_ndwi_analysis(ndwi_prediction.tolist(), pd.to_datetime(pred_timestamp).tolist())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "PrNEiMwYkOY2"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load predictions from CSV\n",
        "pred_eva = pd.read_csv(\"/content/drive/My Drive/EVA_predictions.csv\")\n",
        "\n",
        "# Display loaded predictions\n",
        "print(\"\\nLoaded Predictions:\")\n",
        "print(pred_eva)\n",
        "\n",
        "# Access specific columns if needed\n",
        "evapotranspiration_values = pred_eva['evapotranspiration']\n",
        "print(\"\\nEvapotranspiration Predictions:\")\n",
        "print(evapotranspiration_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Zo6YxIohnXtS"
      },
      "outputs": [],
      "source": [
        "pred_var =  pd.read_csv('/content/drive/My Drive/Temp&Humid_predictions.csv')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "4OTbBU7Olv2k"
      },
      "outputs": [],
      "source": [
        "def analyze_agriculture(temp, humidity, et):\n",
        "    results = {}\n",
        "\n",
        "    ## 1  Crop Water Stress Index (CWSI)\n",
        "    if et == 0:  # Avoid division by zero\n",
        "        results[\" CWSI\"] = 0\n",
        "    else:\n",
        "        # Assuming potential ET is estimated as a function of temp\n",
        "        potential_et = max(5, temp / 10)  # Rough approximation\n",
        "        cwsi = 1 - (et / potential_et)\n",
        "        results[\" CWSI\"] = round(cwsi, 2)\n",
        "\n",
        "        if cwsi > 0.8:\n",
        "            results[\" Irrigation Need\"] = \" Critical stress - Immediate irrigation required!\"\n",
        "        elif 0.5 < cwsi <= 0.8:\n",
        "            results[\" Irrigation Need\"] = \" Moderate stress - Irrigation recommended soon.\"\n",
        "        else:\n",
        "            results[\" Irrigation Need\"] = \" Low stress - No urgent irrigation needed.\"\n",
        "\n",
        "    ## 2  Plant Disease Risk (Fungal Infections like Rust, Blight)\n",
        "    if 15 <= temp <= 25 and humidity > 80:\n",
        "        results[\" Disease Risk\"] = \" High - Favorable conditions for fungal infections!\"\n",
        "    elif 25 < temp <= 30 and humidity > 70:\n",
        "        results[\" Disease Risk\"] = \" Medium - Possible risk for diseases.\"\n",
        "    else:\n",
        "        results[\" Disease Risk\"] = \" Low - Unfavorable conditions for fungal infections.\"\n",
        "\n",
        "    ## 3  Drought Prediction\n",
        "    if humidity < 30 and temp > 35 and et > 5:\n",
        "        results[\" Drought Risk\"] = \" Severe - High risk of drought development!\"\n",
        "    elif humidity < 40 and temp > 32 and et > 4:\n",
        "        results[\" Drought Risk\"] = \" Moderate - Drought conditions possible.\"\n",
        "    else:\n",
        "        results[\" Drought Risk\"] = \" Low - No immediate drought concerns.\"\n",
        "\n",
        "    ## 4  Fog & Dew Formation\n",
        "    dew_point = temp - ((100 - humidity) / 5)\n",
        "    results[\" Dew Point\"] = round(dew_point, 2)\n",
        "\n",
        "    if humidity > 90 and abs(temp - dew_point) < 2:\n",
        "        results[\" Fog Risk\"] = \" High - Expect fog formation.\"\n",
        "    else:\n",
        "        results[\" Fog Risk\"] = \" Low - No significant fog expected.\"\n",
        "\n",
        "    ## 5  Irrigation Scheduling (Based on ET)\n",
        "    if et > 5:\n",
        "        results[\" Irrigation Recommendation\"] = \" High ET  Increase irrigation frequency.\"\n",
        "    elif et > 3:\n",
        "        results[\" Irrigation Recommendation\"] = \" Moderate ET  Regular irrigation required.\"\n",
        "    else:\n",
        "        results[\" Irrigation Recommendation\"] = \" Low ET  Minimal irrigation needed.\"\n",
        "\n",
        "    ## 6  Heatwave Risk & Thermal Comfort Index\n",
        "    humidex = temp + (0.5555 * (6.112 * 10**((7.5 * temp) / (237.7 + temp)) * humidity / 100 - 10))\n",
        "    results[\" Humidex\"] = round(humidex, 2)\n",
        "\n",
        "    if humidex > 45:\n",
        "        results[\" Heatwave Alert\"] = \" Extreme - Dangerous heat conditions!\"\n",
        "    elif 40 <= humidex <= 45:\n",
        "        results[\" Heatwave Alert\"] = \" High - Avoid prolonged exposure.\"\n",
        "    else:\n",
        "        results[\" Heatwave Alert\"] = \" Normal - No heatwave concern.\"\n",
        "\n",
        "    return results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kjkP4yJrmavU"
      },
      "outputs": [],
      "source": [
        "data = analyze_agriculture(temp=38, humidity=25, et=5.8)\n",
        "\n",
        "for key, value in data.items():\n",
        "    print(f\"{key}: {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "YVvbyFGiUNCt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "l7Dlsf9hUN5C"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOYY2d7UIVzG5adFwxlk3l8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}